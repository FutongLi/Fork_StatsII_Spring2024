saveRDS(dfm22, "data/dfm22")
# save our data for next time
saveRDS(dfm24, "data/dfm24")
docvars(dfm_sentiment, "prop_negative")
ggplot(data = NULL) +
geom_point(aes(yday(corpSum24$date), corpSum24$ttr), col = "red") +
geom_point(aes(yday(corpSum23$date), corpSum23$ttr), col = "blue") +
geom_smooth(aes(yday(corpSum24$date), corpSum24$ttr), col = "red") +
geom_smooth(aes(yday(corpSum23$date), corpSum23$ttr), col = "blue")
ggplot(data = NULL) +
geom_density(aes(yday(corpSum24$date)), color = "red") +
geom_density(aes(yday(corpSum23$date)), color = "blue")
ggplot(data = NULL) +
geom_point(aes(yday(corpSum24$date), corpSum24$ttr), col = "red") +
geom_point(aes(yday(corpSum23$date), corpSum23$ttr), col = "blue") +
geom_smooth(aes(yday(corpSum24$date), corpSum24$ttr), col = "red") +
geom_smooth(aes(yday(corpSum23$date), corpSum23$ttr), col = "blue")
View(tidy23)
# This allows us to analyse and compare keyness across years
set.seed(2023)
dfm_by_date <- dfm_group(dfm_ukr, fill = TRUE, groups = year(dfm_ukr$date))
keyness <- textstat_keyness(dfm_by_date, target = "2023")
textplot_keyness(keyness, labelsize = 3)
textplot_keyness(keyness, labelsize = 3)
# remove objects
rm(list=ls())
getwd()
# set wd for current folder
setwd(/Users/poisson/Documents/GitHub/Fork_StatsII_Spring2024/problemSets/PS01/my_answer)
# set wd for current folder
setwd("/Users/poisson/Documents/GitHub/Fork_StatsII_Spring2024/problemSets/PS01/my_answer")
getwd()
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ecdf(data)
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
ECDF(data)
ECDF
ECDF(1.269)
ECDF(1)
pnorm(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
?ks.test
ks.test(empiricalCDF, pnorm(data))
ks.test(empiricalCDF)
nor <- rnorm(100, mean = 0, sd = 1)
ks.test(data, nor)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(nor)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
ks.test(data, nor)
ECDF_nor <- ecdf(nor)
empiricalCDF_nor <- ECDF_nor(data)
# generate test statistic
D <- max(abs(empiricalCDF - empiricalCDF_nor))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
ks.test(data, nor)
ks.test(data, "pnorm")
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
ks.test(data, "pnorm")
ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
# generate Cauchy random variables
data <- rcauchy(1000, location = 0, scale = 1)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
# generate Cauchy random variables
data <- rcauchy(1000, location = 0, scale = 1)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
# generate Cauchy random variables
data <- rcauchy(1000, location = 0, scale = 1)
# create empirical distribution of observed data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
set.seed(123)
# generate Cauchy random variables
data <- rcauchy(1000, location = 0, scale = 1)
# create empirical distribution of observed data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
ks.test(data, "pnorm", mean = mean(data), sd = sd(data))
ks.test(data, "pnorm")
# generate test statistic
D <- max(abs(empiricalCDF - pnorm(data)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
ks.test(data, "pnorm")
ks.test(data, "pnorm", mean = 0, sd = 1)
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
#
return(p_value)
}
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1
ks_test_normal(data)
ks_test_normal(data)
#
return(paste('p-value ='p_value)
#
return(paste('p-value ='p_value))
#
return(paste('p-value =', p_value))
#
return(D, p_value))
#
return(D, p_value)
#
return(c(D, p_value))
#
return(D)
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
#
return(D)
}
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ks_test_normal(data)
pkstwo(0.1347281, 1000)
lapply("supp"),  pkgTest)
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
install.packages("supp")
library("supp")
library(supp)
install.packages("supp")
library(supp)
class(data)
str(data)
length(data)
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
#p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
p_value <- 1-exp(-2*length(data)*D^2)
#
return(D)
}
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ks_test_normal(data)
ks.test(data, "pnorm", mean = 0, sd = 1)
#
return(p_value)
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
#p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
p_value <- 1-exp(-2*length(data)*D^2)
#
return(p_value)
}
# generate Cauchy random variables
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ks_test_normal(data)
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
#p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 1000)-1)^2*pi^2)/(8*D^2)))
p_value <- 1 - sum((-1)^seq(1:1000) * exp(-2 * (1:100)^2 * D^2))
#
return(p_value)
}
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ks_test_normal(data)
ks.test(data, "pnorm", mean = 0, sd = 1)
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
D <- max(abs(empiricalCDF - normalCDF))
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
normalCDF <- pnorm(data)
D <- max(abs(empiricalCDF - normalCDF))
p_value <- 1 - sum((-1)^seq(1:1000) * exp(-2 * (1:100)^2 * D^2))
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, length(data))-1)^2*pi^2)/(8*D^2)))
#p_value <- 1 - sum((-1)^seq(1:1000) * exp(-2 * (1:100)^2 * D^2))
#
return(p_value)
}
ks_test_normal(data)
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, length(data))-1)^2*pi^2)/(8*D^2)))
#p_value <- 1 - sum((-1)^seq(1:1000) * exp(-2 * (1:100)^2 * D^2))
#
return(D)
}
ks_test_normal(data)
ks.test(data, "pnorm", mean = 0, sd = 1)
set.seed (123)
data <- data.frame(x = runif(200, 1, 10))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
# Define the objective function for OLS regression
ols_objective <- function(beta, x, y) {
y_hat <- beta[1] + beta[2] * x
sum((y - y_hat)^2)
}
# Initial values for beta
initial_beta <- c(0, 1)
# Use the BFGS optimization method to estimate the parameters
result_bfgs <- optim(par = initial_beta, fn = ols_objective, x = data$x, y = data$y, method = "BFGS")
# Estimated coefficients
coefficients_bfgs <- result_bfgs$par
print(coefficients_bfgs)
# Equivalent results using lm()
lm_result <- lm(y ~ x, data)
print(coef(lm_result))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
data$y
data
set.seed (123)
data <- data.frame(x = runif(200, 1, 10))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
# Define the objective function for OLS regression
ols_objective <- function(beta, x, y) {
y_hat <- beta[1] + beta[2] * x
sum((y - y_hat)^2)
}
# Use the BFGS optimization method to estimate the parameters
result_bfgs <- optim(fn = ols_objective, par = 0:1, x = data$x, y = data$y, method = "BFGS")
# Estimated coefficients
print(result_bfgs$par)
# Equivalent results using lm()
lm_result <- lm(y ~ x, data)
print(coef(lm_result))
?optim
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, length(data))-1)^2*pi^2)/(8*D^2)))
#p_value <- 1 - sum((-1)^seq(1:1000) * exp(-2 * (1:100)^2 * D^2))
#return the test statistic and p-value
return(list(D = D, p_value = p_value))
}
# generate Cauchy random variables
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ks_test_normal(data)
ks.test(data, "pnorm", mean = 0, sd = 1)
?ks.test()
ks.test(c(1, 2, 2, 3, 3), c(1, 2, 3, 3, 4, 5, 6), exact = TRUE)
ks.test(c(1, 2, 2, 3, 3),'pnorm')
ks.test(c(1, 2, 2, 3, 3),'pnorm', 0, 1)
ks_test_normal(c(1, 2, 2, 3, 3))
D <- 0.274
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, length(data))-1)^2*pi^2)/(8*D^2)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, l0)-1)^2*pi^2)/(8*D^2)))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 10)-1)^2*pi^2)/(8*D^2)))
p_value
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
d <- D*sqrt(length(data))
#generate p value
p_value <- (sqrt(2*pi)/d) * sum(exp((-(2*seq(1, length(data))-1)^2*pi^2)/(8*d^2)))
#return the test statistic and p-value
return(list(D = D, p_value = p_value))
}
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
ks_test_normal(data)
ks.test(data, "pnorm", mean = 0, sd = 1)
m_multiply <- function(A, B, m) {
C <- matrix(0, nrow = m, ncol = m)
for (i in 1:m) {
for (j in 1:m) {
s <- 0
for (k in 1:m) {
s <- s + A[i, k] * B[k, j]
}
C[i, j] <- s
}
}
return(C)
}
m_power <- function(A, m, n) {
if (n == 1) {
return(A)
}
V <- m_power(A, m, n/2)
B <- m_multiply(V, V, m)
if (n %% 2 == 0) {
return(B)
} else {
return(m_multiply(A, B, m))
}
}
K <- function(n, d) {
s <- d^2 * n
if (s > 7.24 || (s > 3.76 && n > 99)) {
return(1 - 2 * exp(-(2.000071 + 0.331/sqrt(n) + 1.409/n) * s))
}
k <- as.integer(n * d) + 1
m <- 2 * k - 1
h <- k - n * d
H <- matrix(0, nrow = m, ncol = m)
for (i in 1:m) {
for (j in 1:m) {
if (i - j + 1 < 1) {
H[i, j] <- 0
} else {
H[i, j] <- 1
}
}
}
for (i in 1:m) {
H[i, 1] <- H[i, 1] - h^i
H[m, i] <- H[m, i] - h^(m - i)
}
H[m, 1] <- H[m, 1] + ifelse(2 * h - 1 > 0, 2 * h - 1, 0)
for (i in 1:m) {
for (j in 1:m) {
if (i - j + 1 > 0) {
for (g in 1:(i - j + 1)) {
H[i, j] <- H[i, j] / g
}
}
}
}
eH <- 0
Q <- m_power(H, m, n)
s <- Q[k, k]
for (i in 1:n) {
s <- s * i / n
if (s < 1e-140) {
s <- s * 1e140
eH <- eH - 140
}
}
s <- s * 10^eH
return(s)
}
n <- 100
d <- 0.1
p_value <- K(n, d)
print(p_value)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
d <- D
p_value <- K(n, d)
print(p_value)
ks.test(data, "pnorm", mean = 0, sd = 1)
n <- 100
d <- 0.1
p_value <- K(n, d)
print(p_value)
ks.test(data, "pnorm", mean = 0, sd = 1, alternative = 'gr')
ks.test(data, "pnorm", mean = 0, sd = 1, alternative = 'le')
D <- max(abs(empiricalCDF - normalCDF))
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 10)-1)^2*pi^2)/(8*D^2)))
ks.test(data, "pnorm", mean = 0, sd = 1, alternative = 'two.sided')
ks.test(data, "pnorm", mean = 0, sd = 1, alternative = 'greater')
p_value *2
D <- max(abs(empiricalCDF - normalCDF))
D <- 2 * D
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, 10)-1)^2*pi^2)/(8*D^2)))
?limit
?limit
install.packages("calculus")
library(calculus)
library(calculus)
?limit
??limit
?limit
install.packages("mosaic")
library(mosaic)
lim(expression, as = value)
?lim
library(pracma)
install.packages("pracma")
library(pracma)
library(pracma)
?lim
#return the test statistic and p-value
return(list(D = D, p_value = p_value))
ks_test_normal <- function(data){
#create empiral distribution of input data
ECDF <- ecdf(data)
empiricalCDF <- ECDF(data)
#create reference distribution CDF
normalCDF <- pnorm(data)
#generate statistic: largerst absolute difference value
D <- max(abs(empiricalCDF - normalCDF))
#generate p value
p_value <- (sqrt(2*pi)/D) * sum(exp((-(2*seq(1, length(data))-1)^2*pi^2)/(8*D^2)))
#return the test statistic and p-value
return(list(D = D, p_value = p_value))
}
#generate Cauchy random variables
set.seed(123)
data <- rcauchy(1000, location = 0, scale = 1)
#execute the test
ks_test_normal(data)
#check the test
ks.test(data, "pnorm", mean = 0, sd = 1)
set.seed (123)
data <- data.frame(x = runif(200, 1, 10))
data$y <- 0 + 2.75*data$x + rnorm(200, 0, 1.5)
#calculate the RSS for an OLS regression
RSS_ols <- function(beta, x, y) {
y_hat <- beta[1] + beta[2] * x
sum((y - y_hat)^2)
}
#estimate the parameters using BFGS method
bfgs_result <- optim(fn = RSS_ols, par = 0:1, x = data$x, y = data$y, method = "BFGS")
#extract estimated coefficients after optimization
print(bfgs_result$par)
#get the equivalent result using lm()
lm_result <- lm(y ~ x, data)
print(coef(lm_result))
